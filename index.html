<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Library Mobile Website Performance Study</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>
  <body>

    <div class="wrapper">
      <header>
        <h1>Library Mobile Website Performance Study</h1>
        <p>Results from a mass analysis of library mobile sites.</p>

        <p class="view">
          <a href="https://github.com/phette23/library-mobile-performance-study">View on GitHub</a>
        </p>


        <ul>
          <li><a href="https://github.com/phette23/library-mobile-performance-study/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/phette23/library-mobile-performance-study/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/phette23/library-mobile-performance-study">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>

      <section>
<h3>
<a name="introduction" class="anchor" href="#introduction"></a>Introduction
</h3>

<p>I'll introduce things here, yeah.</p>

<h3>
<a name="methodology" class="anchor" href="#methodology"></a>Methodology
</h3>

<p>Outline:<br>
  [x] scrape M-libraries<br>
  [x] manually remove misleading links (e.g. screenshots)<br>
  [x] determine Alexa Top 10<br>
  [x] look up mobile sites for top 10<br>
  [ ] run tests<br>
  [ ] look at statistics on the results.
</p>

<p>To obtain a large sample of library mobile websites, I scraped URLs from <a href="http://www.libsuccess.org/index.php?title=M-Libraries">the M-Libraries page</a> of the Library Success wiki. The script which harvests URLs <a href="https://github.com/phette23/library-mobile-performance-study/blob/master/parse-m-libraries.js">is included in the git repository</a>. It takes the hrefs of all anchors elements in the <q>Mobile interfaces (and/or <abbr title="Online Public Access Catalog">OPACS</abbr>)</q> section, which includes several links to screenshots and other miscellany that I manually removed.</p>

<p>To compare library sites against a common metric that most people would be familiar with, I chose to look up the top ten most-visited websites in the United States <a href="http://www.alexa.com/topsites/countries/US">using Alexa</a>. There are certainly only services which claim to know the top websites, and taking a global view would have resulting in a different set, too.</p>

<p>Alexa doesn't list the top sites specifically for mobile devices, so to determine which of the top ten sites have separate mobile sites I spoofed an iPhone using <code>curl</code> by running the following:</p>

<pre><code>curl -LIA "Mozilla/5.0 (iPhone; CPU iPhone OS 6_0_1 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/6.0 Mobile/10A523 Safari/8536.25" $URL
</code></pre>

<p>where <code>$URL</code> is the desktop URL listed in Alexa. For the top ten sites, half used the same URL while half redirected to a mobile-specific location, e.g. m.facebook.com.</p>

<p>Already, this introduces slight inaccuracies in a performance analysis because how a user ends up on a mobile page already affects their experience. While the way my tests are run assume users start on their destination URL, that's not necessarily true. At their worst, some of the Alexa sites perform multiple redirects before landing on the mobile URL. Library sites, too, might require redirect before users get the experience optimized for their device. On the whole, while redirects should only account for a couple HTTP requests at most (and ideally only the first time a user accesses your site on a device), they're still to be avoided and can cause a noticeable page load delay. [ref: Souders first book]</p>

<h3>
<a name="limitations" class="anchor" href="#limitations"></a>Limitations
</h3>

<ul>
<li>The list of library mobile sites is not comprehensive & probably very self-selecting, as only libraries aware of the Library Success wiki would bother listing their site there.
<li>Furthermore, there's no gaurantee that sites listed are current; URLs may have changed or the institution's may have changed strategies, using a single responsive design for instance.
<li>Since only the URLs listed in the wiki were tested, this doesn't perform a comprehensive test of any institution's mobile presence. While some places listed a couple URLs, often a home page and a catalog, my method doesn't crawl an entire site while testing each page.
<li>YSlow
  <ul>
  <li>does not measure what really matters in performance, e.g. the user's experience of how quickly a site loads (which â‰  page load time) & reacts to interaction.
  <li>does measure a number of important aspects which generally correlate with improved performance.
  <li>The subset of YSlow's many metrics is fairly arbitrary, they tend to be things that I personally think are important & easy to understand/improve.
  <li>The "JS Bottom Grade" proved to be flawed as it returned 100% for every single URL tested. I can manually observe that no every site puts their JavaScript at the bottom, so this must be a YSlow bug.
  </ul>
</ul>

<h3>
<a name="results" class="anchor" href="#results"></a>Results
</h3>

<p>Results, complete with graphs.</p>

<h3>
<a name="references" class="anchor" href="#references"></a>References
</h3>

<p>If I referenced anything, it'll go here.</p>

      </section>

      <footer>
        <p>by <a href="https://github.com/phette23">phette23</a></p>
        <p>
          <small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small>
        </p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>

  </body>
</html>
